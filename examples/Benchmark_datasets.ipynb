{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn import metrics as me\n",
    "from sklearn.metrics import classification_report,auc,r2_score,matthews_corrcoef,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import chi2,f_classif,f_regression\n",
    "from catboost import CatBoostRegressor,CatBoostClassifier\n",
    "from catboost.utils import get_roc_curve\n",
    "from catboost import Pool, cv\n",
    "import shap\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "import copy\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "from BorutaShap import BorutaShap\n",
    "from powershap  import PowerShap\n",
    "import shapicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_calc_print(Y,Y_pred,print_bool):\n",
    "    if len(Y_pred) > 1:\n",
    "        R2_total = me.r2_score(Y,Y_pred)\n",
    "    else:\n",
    "        R2_total = -1\n",
    "    RMSE_total = sqrt(me.mean_squared_error(Y,Y_pred))\n",
    "    MAE_total = me.mean_absolute_error(Y,Y_pred)\n",
    "    ME_total = 0\n",
    "    \n",
    "    diff = np.subtract(Y_pred,Y)\n",
    "    for i in range(0,len(diff)):\n",
    "        ME_total+=diff[i]\n",
    "        \n",
    "    ME_total = ME_total/len(diff)\n",
    "    \n",
    "    if print_bool:\n",
    "        print(tabulate([[RMSE_total, MAE_total,R2_total,ME_total]], [\"RMSE\",\"MAE\",\"R²\",\"ME\"], tablefmt=\"grid\"))\n",
    "        #print(f\"RMSE of total: {RMSE_total:.4f}\")\n",
    "        #print(f\"MAE of total: {MAE_total:.4f}\")\n",
    "        #print(f\"R² of total: {R2_total:.4f}\")\n",
    "        #print(f\"ME of total: {ME_total:.4f}\")\n",
    "        #print(f\"MAPE of total: {MAPE_total:.4f}%\")\n",
    "        #print(f\"MdAPE of total: {MdAPE_total:.4f}%\")\n",
    "        #print(f\"MdPE of total: {MdPE_total:.4f}%\")\n",
    "        #print(f\"Std of results: {std_arr:.4f}\")\n",
    "        #print(\"\\n\")\n",
    "    else:\n",
    "        return {\"R2\":R2_total,\"RMSE\":RMSE_total,\"MAE\":MAE_total,\"ME\":ME_total}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,classification_report,auc,r2_score,matthews_corrcoef\n",
    "\n",
    "## This cross_validation is different from the standard cross validation, because the a priori dataset is only tested on actual a priori samples\n",
    "# Inp_db:pandas_DataFrame = input database (contains labels and features), should contain heroi2c numbers as IDs, previous concentrations\n",
    "# Features:List = features to use\n",
    "# Folds:int = amount of folds\n",
    "# RS:int = Random state\n",
    "# Output:dict = dictionary with the results of each fold\n",
    "def benchmark_classification_cross_validation(Model,Inp_db,index_col,folds,RS,features,target_col,disable_tqdm_output=False):\n",
    "    kf = KFold(n_splits=folds,shuffle=True,random_state=RS)\n",
    "\n",
    "    scores_cv_train = {\"AUC\":np.array([]),\n",
    "                 \"MCC\":np.array([]),      \n",
    "                 \"ACCURACY\":np.array([]),\n",
    "                 \"RECALL\":np.array([]),\n",
    "                 \"F1\":np.array([]),\n",
    "                 \"PRECISION\":np.array([])}\n",
    "    \n",
    "    scores_cv_test = {\"AUC\":np.array([]),\n",
    "                 \"MCC\":np.array([]),      \n",
    "                 \"ACCURACY\":np.array([]),\n",
    "                 \"RECALL\":np.array([]),\n",
    "                 \"F1\":np.array([]),\n",
    "                 \"PRECISION\":np.array([])}\n",
    "    \n",
    "    for CV_train_idx, CV_test_idx in tqdm(kf.split(Inp_db[index_col].unique()),disable=disable_tqdm_output):  \n",
    "        ## Split per patient (to avoid data leakage)\n",
    "        X_CV_train = Inp_db[Inp_db[index_col].isin(Inp_db[index_col].unique()[CV_train_idx])]\n",
    "        X_CV_test = Inp_db[Inp_db[index_col].isin(Inp_db[index_col].unique()[CV_test_idx])]\n",
    "        \n",
    "        Y_CV_train = X_CV_train[target_col].values\n",
    "        Y_CV_test = X_CV_test[target_col].values\n",
    "        \n",
    "        ## Extract the required features\n",
    "        X_CV_train_feat = X_CV_train[features]\n",
    "        X_CV_test_feat = X_CV_test[features]\n",
    "        \n",
    "        try:\n",
    "            Model.fit(X_CV_train_feat,Y_CV_train,eval_set=(X_CV_test[features],Y_CV_test))\n",
    "        except:\n",
    "            Model.fit(X_CV_train_feat,Y_CV_train)\n",
    "        \n",
    "        Y_CV_predict_test = Model.predict(X_CV_test_feat)\n",
    "        Y_CV_predict_train = Model.predict(X_CV_train_feat)\n",
    "        y_cv_train_pred = Model.predict_proba(X_CV_train_feat)[:,1]\n",
    "        y_cv_test_pred = Model.predict_proba(X_CV_test_feat)[:,1]\n",
    "        \n",
    "        train_results = classification_report(Y_CV_train,Model.predict(X_CV_train_feat),output_dict=True)\n",
    "        test_results = classification_report(Y_CV_test,Model.predict(X_CV_test_feat),output_dict=True)\n",
    "        \n",
    "        scores_cv_train[\"AUC\"]=np.append(scores_cv_train[\"AUC\"],roc_auc_score(Y_CV_train,y_cv_train_pred))\n",
    "        scores_cv_test[\"AUC\"]=np.append(scores_cv_test[\"AUC\"],roc_auc_score(Y_CV_test,y_cv_test_pred))\n",
    "\n",
    "        scores_cv_train[\"MCC\"]=np.append(scores_cv_train[\"MCC\"],matthews_corrcoef(Y_CV_train,Model.predict(X_CV_train_feat)))\n",
    "        scores_cv_test[\"MCC\"]=np.append(scores_cv_test[\"MCC\"],matthews_corrcoef(Y_CV_test,Model.predict(X_CV_test_feat)))\n",
    "        \n",
    "        scores_cv_train[\"ACCURACY\"]=np.append(scores_cv_train[\"ACCURACY\"],train_results[\"accuracy\"])\n",
    "        scores_cv_test[\"ACCURACY\"]=np.append(scores_cv_test[\"ACCURACY\"],test_results[\"accuracy\"])\n",
    "\n",
    "        scores_cv_train[\"RECALL\"]=np.append(scores_cv_train[\"RECALL\"],train_results['weighted avg']['recall'])\n",
    "        scores_cv_test[\"RECALL\"]=np.append(scores_cv_test[\"RECALL\"],test_results['weighted avg']['recall'])\n",
    "\n",
    "        scores_cv_train[\"F1\"]=np.append(scores_cv_train[\"F1\"],train_results['weighted avg']['f1-score'])\n",
    "        scores_cv_test[\"F1\"]=np.append(scores_cv_test[\"F1\"],test_results['weighted avg']['f1-score'])\n",
    "\n",
    "        scores_cv_train[\"PRECISION\"]=np.append(scores_cv_train[\"PRECISION\"],train_results['weighted avg']['precision'])\n",
    "        scores_cv_test[\"PRECISION\"]=np.append(scores_cv_test[\"PRECISION\"],test_results['weighted avg']['precision'])\n",
    "\n",
    "    #for key in scores_cv_train:\n",
    "    #    scores_cv_train[key]=[np.mean(scores_cv_train[key][0]),np.std(scores_cv_train[key][0])]\n",
    "    #    scores_cv_test[key]=[np.mean(scores_cv_test[key][0]),np.std(scores_cv_test[key][0])]\n",
    "\n",
    "    return scores_cv_train,scores_cv_test\n",
    "\n",
    "## This cross_validation is different from the standard cross validation, because the a priori dataset is only tested on actual a priori samples\n",
    "# Inp_db:pandas_DataFrame = input database (contains labels and features), should contain heroi2c numbers as IDs, previous concentrations\n",
    "# Features:List = features to use\n",
    "# Folds:int = amount of folds\n",
    "# RS:int = Random state\n",
    "# Output:dict = dictionary with the results of each fold\n",
    "def benchmark_regression_cross_validation(Model,Inp_db,index_col,folds,RS,features,target_col,disable_tqdm_output=False):\n",
    "    kf = KFold(n_splits=folds,shuffle=True,random_state=RS)\n",
    "\n",
    "    scores_cv_train = {\"R2\":np.array([]),\n",
    "                 \"RMSE\":np.array([]),      \n",
    "                 \"MAE\":np.array([]),\n",
    "                 \"ME\":np.array([])}\n",
    "    \n",
    "    scores_cv_test = {\"R2\":np.array([]),\n",
    "                 \"RMSE\":np.array([]),      \n",
    "                 \"MAE\":np.array([]),\n",
    "                 \"ME\":np.array([])}\n",
    "    \n",
    "    for CV_train_idx, CV_test_idx in tqdm(kf.split(Inp_db[index_col].unique()),disable=disable_tqdm_output): \n",
    "        ## Split per patient (to avoid data leakage)\n",
    "        X_CV_train = Inp_db[Inp_db[index_col].isin(Inp_db[index_col].unique()[CV_train_idx])]\n",
    "        X_CV_test = Inp_db[Inp_db[index_col].isin(Inp_db[index_col].unique()[CV_test_idx])]\n",
    "        \n",
    "        Y_CV_train = X_CV_train[target_col].values\n",
    "        Y_CV_test = X_CV_test[target_col].values\n",
    "        \n",
    "        ## Extract the required features\n",
    "        X_CV_train_feat = X_CV_train[features]\n",
    "        X_CV_test_feat = X_CV_test[features]\n",
    "        \n",
    "        try:\n",
    "            Model.fit(X_CV_train_feat,Y_CV_train,eval_set=(X_CV_test[features],Y_CV_test))\n",
    "        except:\n",
    "            Model.fit(X_CV_train_feat,Y_CV_train)\n",
    "        \n",
    "        Y_CV_predict_test = Model.predict(X_CV_test_feat)\n",
    "        Y_CV_predict_train = Model.predict(X_CV_train_feat)\n",
    "        \n",
    "        train_results = scores_calc_print(Y_CV_train,Model.predict(X_CV_train_feat),print_bool=False)\n",
    "        test_results = scores_calc_print(Y_CV_test,Model.predict(X_CV_test_feat),print_bool=False)\n",
    "        \n",
    "        scores_cv_train[\"R2\"]=np.append(scores_cv_train[\"R2\"],train_results[\"R2\"])\n",
    "        scores_cv_test[\"R2\"]=np.append(scores_cv_test[\"R2\"],test_results[\"R2\"])\n",
    "\n",
    "        scores_cv_train[\"RMSE\"]=np.append(scores_cv_train[\"RMSE\"],train_results[\"RMSE\"])\n",
    "        scores_cv_test[\"RMSE\"]=np.append(scores_cv_test[\"RMSE\"],test_results[\"RMSE\"])\n",
    "        \n",
    "        scores_cv_train[\"MAE\"]=np.append(scores_cv_train[\"MAE\"],train_results[\"MAE\"])\n",
    "        scores_cv_test[\"MAE\"]=np.append(scores_cv_test[\"MAE\"],test_results[\"MAE\"])\n",
    "\n",
    "        scores_cv_train[\"ME\"]=np.append(scores_cv_train[\"ME\"],train_results['ME'])\n",
    "        scores_cv_test[\"ME\"]=np.append(scores_cv_test[\"ME\"],test_results['ME'])\n",
    "\n",
    "    #for key in scores_cv_train:\n",
    "    #    scores_cv_train[key]=[np.mean(scores_cv_train[key][0]),np.std(scores_cv_train[key][0])]\n",
    "    #    scores_cv_test[key]=[np.mean(scores_cv_test[key][0]),np.std(scores_cv_test[key][0])]\n",
    "\n",
    "    return scores_cv_train,scores_cv_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "\n",
    "def classification_forward_feature_selection(Model,Inp_db,index_col,folds,RS,features,target_col,metric):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    MAEs_train = []  \n",
    "    MAEs_test = []\n",
    "    Metrics_best = {\"AUC\":0.5,\"MCC\":0,\"ACCURACY\":0,\"RECALL\":0,\"F1\":0,\"PRECISION\":0}\n",
    "    temp_mean_sc = {\"AUC\":0.5,\"MCC\":0,\"ACCURACY\":0,\"RECALL\":0,\"F1\":0,\"PRECISION\":0}\n",
    "    Metric_changed = True\n",
    "\n",
    "    CV_features_all = features\n",
    "    CV_features_current_best = []\n",
    "    CV_features_arr_final = []\n",
    "\n",
    "    CV_RS = RS\n",
    "\n",
    "    #Forward feature selection method\n",
    "    while Metric_changed:\n",
    "        print(60*\"=\")\n",
    "        print(\"Iteration to select the \"+str(len(CV_features_arr_final)+1)+\"th feature.\")\n",
    "\n",
    "        #To keep the feature selection going\n",
    "        Metric_changed = False\n",
    "\n",
    "        for cv_feature in tqdm(CV_features_all,ascii=True):#iterator_array,ascii=True):\n",
    "            if cv_feature not in CV_features_arr_final:\n",
    "                try:\n",
    "                    CV_features_current = CV_features_arr_final+[cv_feature]\n",
    "\n",
    "                    try:\n",
    "                        CB_model_cv = Model.copy()\n",
    "                    except:\n",
    "                        CB_model_cv = clone(Model) \n",
    "\n",
    "                    train_sc,test_sc = benchmark_classification_cross_validation(Model,Inp_db,\n",
    "                                                                                 index_col,folds,RS,\n",
    "                                                                                 CV_features_current,target_col,True)\n",
    "\n",
    "                    for key in test_sc:\n",
    "                        temp_mean_sc[key]=np.mean(test_sc[key])\n",
    "\n",
    "                    if temp_mean_sc[metric]>Metrics_best[metric]:\n",
    "                        for key in temp_mean_sc:\n",
    "                            Metrics_best[key]=temp_mean_sc[key]\n",
    "                        CV_features_current_best = CV_features_current\n",
    "                        Metric_changed = True\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(\"Skipping this feature\")\n",
    "\n",
    "        CV_features_arr_final = CV_features_current_best\n",
    "        print(\"Current features: \"+str(CV_features_arr_final))\n",
    "        print(\"Status update: The current best metrics are: \"+str(Metrics_best))\n",
    "\n",
    "    print(60*\"=\")\n",
    "    print(\"The best metrics are: \"+str(Metrics_best)+\" with the features: \"+str(CV_features_arr_final)) \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return CV_features_arr_final,Metrics_best\n",
    "\n",
    "\n",
    "def regression_forward_feature_selection(Model,Inp_db,index_col,folds,RS,features,target_col,metric):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    MAEs_train = []  \n",
    "    MAEs_test = []\n",
    "    Metrics_best = {\"R2\":-10,\"RMSE\":9999,\"MAE\":9999,\"ME\":9999}\n",
    "    temp_mean_sc = {\"R2\":-10,\"RMSE\":9999,\"MAE\":9999,\"ME\":9999}\n",
    "\n",
    "    Metric_changed = True\n",
    "\n",
    "    CV_features_all = features\n",
    "    CV_features_current_best = []\n",
    "    CV_features_arr_final = []\n",
    "\n",
    "    CV_RS = RS\n",
    "\n",
    "    #Forward feature selection method\n",
    "    while Metric_changed:\n",
    "        print(60*\"=\")\n",
    "        print(\"Iteration to select the \"+str(len(CV_features_arr_final)+1)+\"th feature.\")\n",
    "\n",
    "        #To keep the feature selection going\n",
    "        Metric_changed = False\n",
    "\n",
    "        for cv_feature in tqdm(CV_features_all,ascii=True):#iterator_array,ascii=True):\n",
    "            if cv_feature not in CV_features_arr_final:\n",
    "                try:\n",
    "                    CV_features_current = CV_features_arr_final+[cv_feature]\n",
    "\n",
    "                    try:\n",
    "                        CB_model_cv = Model.copy()\n",
    "                    except:\n",
    "                        CB_model_cv = clone(Model) \n",
    "\n",
    "                    train_sc,test_sc = benchmark_regression_cross_validation(Model,Inp_db,index_col,folds,RS,CV_features_current,target_col,True)\n",
    "\n",
    "                    for key in test_sc:\n",
    "                        temp_mean_sc[key]=np.mean(test_sc[key])\n",
    "\n",
    "                    if metric == \"R2\":\n",
    "                        if temp_mean_sc[metric]>Metrics_best[metric]:\n",
    "                            for key in temp_mean_sc:\n",
    "                                Metrics_best[key]=temp_mean_sc[key]\n",
    "                            CV_features_current_best = CV_features_current\n",
    "                            Metric_changed = True\n",
    "                    else:\n",
    "                        if temp_mean_sc[metric]<Metrics_best[metric]:\n",
    "                            for key in temp_mean_sc:\n",
    "                                Metrics_best[key]=temp_mean_sc[key]\n",
    "                            CV_features_current_best = CV_features_current\n",
    "                            Metric_changed = True\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(\"Skipping this feature\")\n",
    "\n",
    "        CV_features_arr_final = CV_features_current_best\n",
    "        print(\"Current features: \"+str(CV_features_arr_final))\n",
    "        print(\"Status update: The current best metrics are: \"+str(Metrics_best))\n",
    "\n",
    "    print(60*\"=\")\n",
    "    print(\"The best metrics are: \"+str(Metrics_best)+\" with the features: \"+str(CV_features_arr_final)) \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return CV_features_arr_final,Metrics_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def classification_backwards_feature_selection(Model,Inp_db,index_col,folds,RS,features,target_col,metric):\n",
    "    start_time = time.time()\n",
    "    MAEs_train = []  \n",
    "    MAEs_test = []\n",
    "    Metrics_best = {\"AUC\":0.5,\"MCC\":0,\"ACCURACY\":0,\"RECALL\":0,\"F1\":0,\"PRECISION\":0}\n",
    "    temp_mean_sc = {\"AUC\":0.5,\"MCC\":0,\"ACCURACY\":0,\"RECALL\":0,\"F1\":0,\"PRECISION\":0}\n",
    "    Metric_changed = True\n",
    "\n",
    "    CV_features_all = list(features)\n",
    "    CV_features_current_best = []\n",
    "    CV_features_arr_final = list(features)\n",
    "\n",
    "    CV_RS = RS\n",
    "    \n",
    "    print(\"Getting the best metrics\")\n",
    "        #first test         \n",
    "    train_sc,test_sc = benchmark_classification_cross_validation(Model,Inp_db,\n",
    "                                         index_col,folds,RS,\n",
    "                                         CV_features_all,target_col,True)\n",
    "    for key in test_sc:\n",
    "        Metrics_best[key]=np.mean(test_sc[key])\n",
    "    print(\"Status update: The current best metrics are: \"+str(Metrics_best))\n",
    "\n",
    "    #Backwards feature selection method\n",
    "    while Metric_changed:\n",
    "        print(60*\"=\")\n",
    "        print(\"Iteration to delete the \"+str(len(CV_features_arr_final)+1)+\"th feature.\")\n",
    "\n",
    "        #To keep the feature selection going\n",
    "        Metric_changed = False\n",
    "\n",
    "        for cv_feature in tqdm(CV_features_all,ascii=True):#iterator_array,ascii=True):\n",
    "            if cv_feature in CV_features_arr_final:\n",
    "                CV_features_current = copy.deepcopy(CV_features_all)\n",
    "                CV_features_current.remove(cv_feature)\n",
    "\n",
    "                CB_model_cv = Model.copy()\n",
    "\n",
    "                train_sc,test_sc = benchmark_classification_cross_validation(Model,Inp_db,\n",
    "                                                                             index_col,folds,RS,\n",
    "                                                                             CV_features_current,target_col,True)\n",
    "\n",
    "                for key in test_sc:\n",
    "                    temp_mean_sc[key]=np.mean(test_sc[key])\n",
    "\n",
    "                if temp_mean_sc[metric]>Metrics_best[metric]:\n",
    "                    for key in temp_mean_sc:\n",
    "                        Metrics_best[key]=temp_mean_sc[key]\n",
    "                    CV_features_current_best = CV_features_current\n",
    "                    Metric_changed = True\n",
    "\n",
    "        CV_features_arr_final = CV_features_current_best\n",
    "        print(\"Current features: \"+str(CV_features_arr_final))\n",
    "        print(\"Status update: The current best metrics are: \"+str(Metrics_best))\n",
    "\n",
    "    print(60*\"=\")\n",
    "    print(\"The best metrics are: \"+str(Metrics_best)+\" with the features: \"+str(CV_features_arr_final)) \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return CV_features_arr_final,Metrics_best\n",
    "\n",
    "\n",
    "def regression_backwards_feature_selection(Model,Inp_db,index_col,folds,RS,features,target_col,metric):\n",
    "    start_time = time.time()\n",
    "    MAEs_train = []  \n",
    "    MAEs_test = []\n",
    "    Metrics_best = {\"R2\":-10,\"RMSE\":9999,\"MAE\":9999,\"ME\":9999}\n",
    "    temp_mean_sc = {\"R2\":-10,\"RMSE\":9999,\"MAE\":9999,\"ME\":9999}\n",
    "    Metric_changed = True\n",
    "\n",
    "    CV_features_all = list(features)\n",
    "    CV_features_current_best = []\n",
    "    CV_features_arr_final = list(features)\n",
    "\n",
    "    CV_RS = RS\n",
    "    \n",
    "    #first test   \n",
    "    print(\"Getting the best metrics\")\n",
    "    train_sc,test_sc = benchmark_regression_cross_validation(Model,Inp_db,\n",
    "                                         index_col,folds,RS,\n",
    "                                         CV_features_all,target_col,True)\n",
    "    for key in test_sc:\n",
    "        Metrics_best[key]=np.mean(test_sc[key])\n",
    "    print(\"Status update: The current best metrics are: \"+str(Metrics_best))\n",
    "\n",
    "\n",
    "    #Forward feature selection method\n",
    "    while Metric_changed:\n",
    "        print(60*\"=\")\n",
    "        print(\"Iteration to delete the \"+str(len(CV_features_arr_final)+1)+\"th feature.\")\n",
    "\n",
    "        #To keep the feature selection going\n",
    "        Metric_changed = False\n",
    "        \n",
    "    \n",
    "        for cv_feature in tqdm(CV_features_all,ascii=True):#iterator_array,ascii=True):\n",
    "            if cv_feature in CV_features_arr_final:\n",
    "                CV_features_current = copy.deepcopy(CV_features_all)\n",
    "                CV_features_current.remove(cv_feature)\n",
    "\n",
    "                CB_model_cv = Model.copy()\n",
    "\n",
    "                train_sc,test_sc = benchmark_regression_cross_validation(Model,Inp_db,\n",
    "                                                                             index_col,folds,RS,\n",
    "                                                                             CV_features_current,target_col,True)\n",
    "\n",
    "                for key in test_sc:\n",
    "                    temp_mean_sc[key]=np.mean(test_sc[key])\n",
    "\n",
    "                if temp_mean_sc[metric]>Metrics_best[metric]:\n",
    "                    for key in temp_mean_sc:\n",
    "                        Metrics_best[key]=temp_mean_sc[key]\n",
    "                    CV_features_current_best = CV_features_current\n",
    "                    Metric_changed = True\n",
    "\n",
    "        CV_features_arr_final = CV_features_current_best\n",
    "        print(\"Current features: \"+str(CV_features_arr_final))\n",
    "        print(\"Status update: The current best metrics are: \"+str(Metrics_best))\n",
    "\n",
    "    print(60*\"=\")\n",
    "    print(\"The best metrics are: \"+str(Metrics_best)+\" with the features: \"+str(CV_features_arr_final)) \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return CV_features_arr_final,Metrics_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,classification_report,auc,r2_score,matthews_corrcoef\n",
    "\n",
    "## This cross_validation is different from the standard cross validation, because the a priori dataset is only tested on actual a priori samples\n",
    "# Inp_db:pandas_DataFrame = input database (contains labels and features), should contain heroi2c numbers as IDs, previous concentrations\n",
    "# Features:List = features to use\n",
    "# Folds:int = amount of folds\n",
    "# RS:int = Random state\n",
    "# Output:dict = dictionary with the results of each fold\n",
    "def test_bootstrap_eval_class(Model,test_df,bootstrap_its,RS,features,target_col,disable_tqdm_output=False):\n",
    "    scores_cv_test = {\"AUC\":np.array([]),\n",
    "                 \"MCC\":np.array([]),      \n",
    "                 \"ACCURACY\":np.array([]),\n",
    "                 \"RECALL\":np.array([]),\n",
    "                 \"F1\":np.array([]),\n",
    "                 \"PRECISION\":np.array([])}\n",
    "    \n",
    "    for i in tqdm(range(bootstrap_its)):\n",
    "        sampled_df = test_df.sample(n=int(0.66*len(test_df)),replace=True,random_state=i)\n",
    "\n",
    "        Y_CV_test = sampled_df[target_col].values\n",
    "        ## Extract the required features\n",
    "        X_CV_test_feat = sampled_df[features].values\n",
    "\n",
    "        Y_CV_predict_test = Model.predict(X_CV_test_feat)\n",
    "        y_cv_test_pred = Model.predict_proba(X_CV_test_feat)[:,1]\n",
    "\n",
    "        test_results = classification_report(Y_CV_test,Y_CV_predict_test,output_dict=True)\n",
    "\n",
    "        scores_cv_test[\"AUC\"]=np.append(scores_cv_test[\"AUC\"],roc_auc_score(Y_CV_test,y_cv_test_pred))\n",
    "        scores_cv_test[\"MCC\"]=np.append(scores_cv_test[\"MCC\"],matthews_corrcoef(Y_CV_test,Y_CV_predict_test))\n",
    "        scores_cv_test[\"ACCURACY\"]=np.append(scores_cv_test[\"ACCURACY\"],test_results[\"accuracy\"])\n",
    "        scores_cv_test[\"RECALL\"]=np.append(scores_cv_test[\"RECALL\"],test_results['weighted avg']['recall'])\n",
    "        scores_cv_test[\"F1\"]=np.append(scores_cv_test[\"F1\"],test_results['weighted avg']['f1-score'])\n",
    "        scores_cv_test[\"PRECISION\"]=np.append(scores_cv_test[\"PRECISION\"],test_results['weighted avg']['precision'])\n",
    "\n",
    "    return scores_cv_test\n",
    "\n",
    "## This cross_validation is different from the standard cross validation, because the a priori dataset is only tested on actual a priori samples\n",
    "# Inp_db:pandas_DataFrame = input database (contains labels and features), should contain heroi2c numbers as IDs, previous concentrations\n",
    "# Features:List = features to use\n",
    "# Folds:int = amount of folds\n",
    "# RS:int = Random state\n",
    "# Output:dict = dictionary with the results of each fold\n",
    "def test_bootstrap_eval_regres(Model,test_df,bootstrap_its,RS,features,target_col,disable_tqdm_output=False):\n",
    "\n",
    "    scores_cv_train = {\"R2\":np.array([]),\n",
    "                 \"RMSE\":np.array([]),      \n",
    "                 \"MAE\":np.array([]),\n",
    "                 \"ME\":np.array([])}\n",
    "    \n",
    "    scores_cv_test = {\"R2\":np.array([]),\n",
    "                 \"RMSE\":np.array([]),      \n",
    "                 \"MAE\":np.array([]),\n",
    "                 \"ME\":np.array([])}\n",
    "    \n",
    "    for i in tqdm(range(bootstrap_its)):\n",
    "        ## Split per patient (to avoid data leakage)\n",
    "        sampled_df = test_df.sample(n=int(0.66*len(test_df)),replace=True,random_state=i)\n",
    "\n",
    "        Y_CV_test = sampled_df[target_col].values\n",
    "        ## Extract the required features\n",
    "        X_CV_test_feat = sampled_df[features]\n",
    "\n",
    "        Y_CV_predict_test = Model.predict(X_CV_test_feat)\n",
    "        test_results = scores_calc_print(Y_CV_test,Model.predict(X_CV_test_feat),print_bool=False)\n",
    "        \n",
    "        scores_cv_test[\"R2\"]=np.append(scores_cv_test[\"R2\"],test_results[\"R2\"])\n",
    "        scores_cv_test[\"RMSE\"]=np.append(scores_cv_test[\"RMSE\"],test_results[\"RMSE\"])\n",
    "        scores_cv_test[\"MAE\"]=np.append(scores_cv_test[\"MAE\"],test_results[\"MAE\"])\n",
    "        scores_cv_test[\"ME\"]=np.append(scores_cv_test[\"ME\"],test_results['ME'])\n",
    "\n",
    "    return scores_cv_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADELON dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = pd.read_csv(\"data/madelon.csv\")\n",
    "current_df = current_df.reset_index()\n",
    "current_df.loc[current_df.Class==0,\"Class\"]=-1#0\n",
    "train_idx,val_idx = train_test_split(current_df[\"index\"],test_size=0.25,random_state = 1)\n",
    "current_db_train = current_df[current_df[\"index\"].isin(train_idx)]\n",
    "current_db_test = current_df[current_df[\"index\"].isin(val_idx)]\n",
    "\n",
    "target_col = \"Class\"\n",
    "Index_col = \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_db_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Powershap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = PowerShap(\n",
    "    model = CatBoostClassifier(verbose=0, n_estimators=250,use_best_model=True),\n",
    "    power_iterations=10,automatic=True, limit_automatic=10,verbose=True,target_col=target_col,index_col=Index_col,\n",
    ")\n",
    "selector.fit(current_db_train.drop(columns=[Index_col,target_col]), current_db_train[target_col])\n",
    "t = selector._processed_shaps_df\n",
    "#t.reset_index().to_csv(\"results/madelon_PowerSHAP_catboost_results_automatic_mode.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borutashap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(verbose=False,iterations=250)#,use_best_model=True)\n",
    "\n",
    "# if classification is False it is a Regression problem\n",
    "Feature_Selector = BorutaShap(model=model,\n",
    "                              importance_measure='shap',\n",
    "                              classification=True)\n",
    "\n",
    "Feature_Selector.fit(X=current_db_train[list(current_db_train.columns.values[1:-1])], y=current_db_train[target_col], sample=False,\n",
    "                        train_or_test = 'test', normalize=True,verbose=True)\n",
    "subset = Feature_Selector.Subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp_db = current_db_train.copy(deep=True)\n",
    "train_idx,val_idx = train_test_split(Inp_db[Index_col],test_size=0.2,random_state = 0)\n",
    "\n",
    "X_train = Inp_db[Inp_db[Index_col].isin(train_idx)].copy(deep=True).drop(columns=[Index_col,target_col])\n",
    "X_val = Inp_db[Inp_db[Index_col].isin(val_idx)].copy(deep=True).drop(columns=[Index_col,target_col])\n",
    "Y_train = Inp_db[Inp_db[Index_col].isin(train_idx)][target_col]\n",
    "\n",
    "# LightGBM in RandomForest-like mode (with rows subsampling), without columns subsampling\n",
    "model = CatBoostClassifier(verbose=False,iterations=250,use_best_model=False)\n",
    "\n",
    "# This is the class (not its instance) of SHAP's TreeExplainer\n",
    "explainer_type = shap.TreeExplainer\n",
    "\n",
    "# Use PandasSelector with 100 iterations\n",
    "selector = shapicant.PandasSelector(model, explainer_type, random_state=42)\n",
    "\n",
    "# Run the feature selection\n",
    "# If we provide a validation set, SHAP values are computed on it, otherwise they are computed on the training set\n",
    "# We can also provide additional parameters to the underlying estimator's fit method through estimator_params\n",
    "selector.fit(X_train, Y_train, X_validation=X_val)#, estimator_params={\"categorical_feature\": None})\n",
    "\n",
    "# Just get the features list\n",
    "selected_features = selector.get_features()\n",
    "\n",
    "# We can also get the p-values as pandas Series\n",
    "p_values = selector.p_values_\n",
    "\n",
    "np.array(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_model = CatBoostClassifier(verbose=False,iterations=250,use_best_model=True)\n",
    "CV_features_arr_final,Metrics_best = classification_forward_feature_selection(shap_model,current_db_train,Index_col,5,0,current_db_train.drop(columns=[target_col,Index_col]).columns.values,target_col,\"AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"chi\"\n",
    "\n",
    "if model == \"forward\":\n",
    "    selected_features = ['V339', 'V242', 'V379', 'V29', 'V456', 'V282', 'V494', 'V129'] #forward feature selection on AUC\n",
    "    \n",
    "elif model ==\"borutashap\":\n",
    "    selected_features = ['V434', 'V242', 'V379', 'V5', 'V476', 'V49', 'V282', 'V286', 'V339','V29'] #borutoSHAP \n",
    "    \n",
    "elif model ==\"powershap\":\n",
    "    processed_shaps_df = pd.read_csv(\"results/madelon_PowerSHAP_catboost_results_automatic_mode.csv\")\n",
    "    selected_features = processed_shaps_df[(processed_shaps_df.p_value<0.01)][\"index\"].values\n",
    "\n",
    "elif model ==\"shapicant\":\n",
    "    #shapicant\n",
    "    selected_features = ['V5', 'V29', 'V49', 'V65', 'V106', 'V129', 'V154', 'V198', 'V205',\n",
    "           'V242', 'V249', 'V282', 'V283', 'V286', 'V305', 'V307', 'V319',\n",
    "           'V337', 'V339', 'V379', 'V425', 'V434', 'V443', 'V452', 'V454',\n",
    "           'V456', 'V472', 'V473', 'V476', 'V494']\n",
    "\n",
    "elif model ==\"chi\":\n",
    "    #chi squared p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[1:-1][np.where(chi2(current_db_train[current_db_train.columns.values[1:-1]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"f_test\":\n",
    "    #f_classif p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[1:-1][np.where(f_classif(current_db_train[current_db_train.columns.values[1:-1]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"default\":\n",
    "    selected_features = list(current_df.columns.values[1:-1])\n",
    "    \n",
    "\n",
    "print(len(selected_features))\n",
    "\n",
    "CB_model = CatBoostClassifier(verbose=False,iterations=250,random_seed=2,use_best_model=True)\n",
    "\n",
    "scores_cv_train,scores_cv_test = benchmark_classification_cross_validation(Model = CB_model,Inp_db = current_db_train.copy(deep=True),index_col=Index_col,folds=10,RS=1,features = selected_features,target_col = target_col)\n",
    "\n",
    "print(model)\n",
    "print(\"TRAIN\")\n",
    "for key in scores_cv_train:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_train[key]),3))+\" (\"+str(np.round(np.std(scores_cv_train[key]),3))+\")\")\n",
    "print(50*\"=\")\n",
    "print(\"TEST\")\n",
    "for key in scores_cv_test:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_test[key]),3))+\" (\"+str(np.round(np.std(scores_cv_test[key]),3))+\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"powershap\"\n",
    "\n",
    "if model == \"forward\":\n",
    "    selected_features = ['V339', 'V242', 'V379', 'V29', 'V456', 'V282', 'V494', 'V129'] #forward feature selection on AUC\n",
    "    \n",
    "elif model ==\"borutashap\":\n",
    "    selected_features = ['V434', 'V242', 'V379', 'V5', 'V476', 'V49', 'V282', 'V286', 'V339','V29'] #borutoSHAP \n",
    "    \n",
    "elif model ==\"powershap\":\n",
    "    processed_shaps_df = pd.read_csv(\"results/madelon_PowerSHAP_catboost_results_automatic_mode.csv\")\n",
    "    selected_features = processed_shaps_df[(processed_shaps_df.p_value<0.01)][\"index\"].values\n",
    "\n",
    "elif model ==\"shapicant\":\n",
    "    #shapicant\n",
    "    selected_features = ['V5', 'V29', 'V49', 'V65', 'V106', 'V129', 'V154', 'V198', 'V205',\n",
    "           'V242', 'V249', 'V282', 'V283', 'V286', 'V305', 'V307', 'V319',\n",
    "           'V337', 'V339', 'V379', 'V425', 'V434', 'V443', 'V452', 'V454',\n",
    "           'V456', 'V472', 'V473', 'V476', 'V494']\n",
    "\n",
    "elif model ==\"chi\":\n",
    "    #chi squared p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[1:-1][np.where(chi2(current_db_train[current_db_train.columns.values[1:-1]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"f_test\":\n",
    "    #f_classif p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[1:-1][np.where(f_classif(current_db_train[current_db_train.columns.values[1:-1]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"default\":\n",
    "    selected_features = list(current_df.columns.values[1:-1])\n",
    "\n",
    "X_train = current_db_train[selected_features]\n",
    "Y_train = current_db_train[target_col]\n",
    "\n",
    "X_test = current_db_test[selected_features]\n",
    "Y_test = current_db_test[target_col]\n",
    "\n",
    "CB_model = CatBoostClassifier(verbose=False,iterations=250,random_seed=2)#,per_float_feature_quantization=['1:border_count=1024'])\n",
    "CB_model.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "scores_cv_test = test_bootstrap_eval_class(Model = CB_model,test_df = current_db_test.copy(deep=True),bootstrap_its=1000,RS=1,features = selected_features,target_col = target_col)\n",
    "\n",
    "print(model)\n",
    "print(\"TEST\")\n",
    "for key in scores_cv_test:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_test[key]),3))+\" (\"+str(np.round(np.std(scores_cv_test[key]),3))+\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINA PRIORI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gina_prior_df = pd.read_csv(\"data/gina_prior.csv\")\n",
    "gina_prior_df = gina_prior_df.reset_index()\n",
    "gina_prior_df.loc[gina_prior_df.label==-1,\"label\"]=0\n",
    "train_idx,val_idx = train_test_split(gina_prior_df[\"index\"],test_size=0.25,random_state = 1)\n",
    "current_db_train = gina_prior_df[gina_prior_df[\"index\"].isin(train_idx)]\n",
    "current_db_test = gina_prior_df[gina_prior_df[\"index\"].isin(val_idx)]\n",
    "\n",
    "target_col = \"label\"\n",
    "Index_col = \"index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Powershap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = PowerShap(\n",
    "    model = CatBoostClassifier(verbose=0, n_estimators=250,use_best_model=True),\n",
    "    power_iterations=10,automatic=True, limit_automatic=10,verbose=True,target_col=target_col,index_col=Index_col,\n",
    ")\n",
    "selector.fit(current_db_train.drop(columns=[Index_col,target_col]), current_db_train[target_col])\n",
    "t = selector._processed_shaps_df\n",
    "#t.reset_index().to_csv(\"results/gina_prior_PowerSHAP_catboost_results_automatic_mode.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borutashap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(verbose=False,iterations=250)#,use_best_model=True)\n",
    "\n",
    "# if classification is False it is a Regression problem\n",
    "Feature_Selector = BorutaShap(model=model,\n",
    "                              importance_measure='shap',\n",
    "                              classification=True)\n",
    "\n",
    "Feature_Selector.fit(X=current_db_train[list(current_db_train.columns.values[1:-1])], y=current_db_train[target_col], sample=False,\n",
    "                        train_or_test = 'test', normalize=True,verbose=True)\n",
    "subset = Feature_Selector.Subset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp_db = current_db_train.copy(deep=True)\n",
    "train_idx,val_idx = train_test_split(Inp_db[Index_col],test_size=0.2,random_state = 0)\n",
    "\n",
    "X_train = Inp_db[Inp_db[Index_col].isin(train_idx)].copy(deep=True).drop(columns=[Index_col,target_col])\n",
    "X_val = Inp_db[Inp_db[Index_col].isin(val_idx)].copy(deep=True).drop(columns=[Index_col,target_col])\n",
    "Y_train = Inp_db[Inp_db[Index_col].isin(train_idx)][target_col]\n",
    "\n",
    "# LightGBM in RandomForest-like mode (with rows subsampling), without columns subsampling\n",
    "model = CatBoostClassifier(verbose=False,iterations=250,use_best_model=False)\n",
    "\n",
    "# This is the class (not its instance) of SHAP's TreeExplainer\n",
    "explainer_type = shap.TreeExplainer\n",
    "\n",
    "# Use PandasSelector with 100 iterations\n",
    "selector = shapicant.PandasSelector(model, explainer_type, random_state=42)\n",
    "\n",
    "# Run the feature selection\n",
    "# If we provide a validation set, SHAP values are computed on it, otherwise they are computed on the training set\n",
    "# We can also provide additional parameters to the underlying estimator's fit method through estimator_params\n",
    "selector.fit(X_train, Y_train, X_validation=X_val)#, estimator_params={\"categorical_feature\": None})\n",
    "\n",
    "# Just get the features list\n",
    "selected_features = selector.get_features()\n",
    "\n",
    "# We can also get the p-values as pandas Series\n",
    "p_values = selector.p_values_\n",
    "\n",
    "np.array(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_model = CatBoostClassifier(verbose=False,iterations=250,use_best_model=True)\n",
    "CV_features_arr_final,Metrics_best = classification_forward_feature_selection(shap_model,current_db_train,Index_col,5,0,current_db_train.drop(columns=[target_col,Index_col]).columns.values,target_col,\"AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"powershap\"\n",
    "\n",
    "if model == \"forward\":\n",
    "    selected_features = ['pixel514', 'pixel324', 'pixel455', 'pixel240', 'pixel544', \n",
    "               'pixel626', 'pixel460', 'pixel154', 'pixel211', 'pixel266', \n",
    "               'pixel457', 'pixel436', 'pixel376', 'pixel383', 'pixel490', 'pixel540', 'pixel242', 'pixel636', \n",
    "               'pixel550', 'pixel630', 'pixel301', 'pixel158', 'pixel627', 'pixel267', 'pixel458', 'pixel223'] #forward feature selection on AUC\n",
    "    \n",
    "elif model ==\"borutashap\":\n",
    "    selected_features = ['pixel543', 'pixel296', 'pixel157', 'pixel455', 'pixel515', 'pixel490', 'pixel352', 'pixel548', 'pixel488', \n",
    "                         'pixel324', 'pixel211', 'pixel351', 'pixel239', 'pixel713', 'pixel269', 'pixel489', 'pixel516', 'pixel460', \n",
    "                         'pixel212', 'pixel513', 'pixel463', 'pixel457', 'pixel514', \n",
    "                         'pixel240', 'pixel241', 'pixel267', 'pixel573', 'pixel487', 'pixel486', 'pixel484', 'pixel268', 'pixel511', \n",
    "                         'pixel485', 'pixel544', 'pixel456', 'pixel213', 'pixel323'] #borutoSHAP \n",
    "    \n",
    "elif model ==\"powershap\":\n",
    "    processed_shaps_df = pd.read_csv(\"results/gina_prior_PowerSHAP_catboost_results_automatic_mode.csv\")\n",
    "    selected_features = processed_shaps_df[(processed_shaps_df.p_value<0.01)][\"index\"].values\n",
    "\n",
    "elif model ==\"shapicant\":\n",
    "    #shapicant\n",
    "    selected_features = ['pixel103', 'pixel104', 'pixel137', 'pixel152', 'pixel153',\n",
    "       'pixel154', 'pixel157', 'pixel158', 'pixel184', 'pixel211',\n",
    "       'pixel212', 'pixel213', 'pixel238', 'pixel239', 'pixel240',\n",
    "       'pixel241', 'pixel242', 'pixel243', 'pixel249', 'pixel251',\n",
    "       'pixel267', 'pixel268', 'pixel269', 'pixel295', 'pixel296',\n",
    "       'pixel297', 'pixel319', 'pixel323', 'pixel324', 'pixel347',\n",
    "       'pixel348', 'pixel351', 'pixel352', 'pixel358', 'pixel359',\n",
    "       'pixel376', 'pixel377', 'pixel383', 'pixel387', 'pixel403',\n",
    "       'pixel404', 'pixel405', 'pixel410', 'pixel414', 'pixel416',\n",
    "       'pixel427', 'pixel428', 'pixel429', 'pixel432', 'pixel438',\n",
    "       'pixel454', 'pixel455', 'pixel456', 'pixel458', 'pixel459',\n",
    "       'pixel460', 'pixel461', 'pixel462', 'pixel463', 'pixel465',\n",
    "       'pixel483', 'pixel484', 'pixel485', 'pixel487', 'pixel488',\n",
    "       'pixel489', 'pixel490', 'pixel498', 'pixel500', 'pixel511',\n",
    "       'pixel513', 'pixel514', 'pixel515', 'pixel516', 'pixel517',\n",
    "       'pixel518', 'pixel528', 'pixel540', 'pixel541', 'pixel543',\n",
    "       'pixel544', 'pixel545', 'pixel546', 'pixel548', 'pixel569',\n",
    "       'pixel572', 'pixel573', 'pixel576', 'pixel579', 'pixel581',\n",
    "       'pixel584', 'pixel585', 'pixel604', 'pixel607', 'pixel611',\n",
    "       'pixel626', 'pixel627', 'pixel630', 'pixel635', 'pixel680',\n",
    "       'pixel709', 'pixel713', 'pixel714', 'pixel716', 'pixel718',\n",
    "       'pixel719']\n",
    "\n",
    "elif model ==\"chi\":\n",
    "    #chi squared p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[1:-1][np.where(chi2(current_db_train[current_db_train.columns.values[1:-1]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"f_test\":\n",
    "    #f_classif p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[1:-1][np.where(f_classif(current_db_train[current_db_train.columns.values[1:-1]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"default\":\n",
    "    selected_features = list(current_db_train.columns.values[1:-1]) \n",
    "\n",
    "print(len(selected_features))\n",
    "\n",
    "CB_model = CatBoostClassifier(verbose=False,iterations=250,random_seed=2,use_best_model=True)\n",
    "\n",
    "scores_cv_train,scores_cv_test = benchmark_classification_cross_validation(Model = CB_model,Inp_db = current_db_train.copy(deep=True),index_col=Index_col,folds=10,RS=0,features = selected_features,target_col = target_col)\n",
    "\n",
    "print(model)\n",
    "print(\"TRAIN\")\n",
    "for key in scores_cv_train:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_train[key]),3))+\" (\"+str(np.round(np.std(scores_cv_train[key]),3))+\")\")\n",
    "print(50*\"=\")\n",
    "print(\"TEST\")\n",
    "for key in scores_cv_test:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_test[key]),3))+\" (\"+str(np.round(np.std(scores_cv_test[key]),3))+\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bootstrap testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"powershap\"\n",
    "\n",
    "if model == \"forward\":\n",
    "    selected_features = ['pixel514', 'pixel324', 'pixel455', 'pixel240', 'pixel544', \n",
    "               'pixel626', 'pixel460', 'pixel154', 'pixel211', 'pixel266', \n",
    "               'pixel457', 'pixel436', 'pixel376', 'pixel383', 'pixel490', 'pixel540', 'pixel242', 'pixel636', \n",
    "               'pixel550', 'pixel630', 'pixel301', 'pixel158', 'pixel627', 'pixel267', 'pixel458', 'pixel223'] #forward feature selection on AUC\n",
    "    \n",
    "elif model ==\"borutashap\":\n",
    "    selected_features = ['pixel543', 'pixel296', 'pixel157', 'pixel455', 'pixel515', 'pixel490', 'pixel352', 'pixel548', 'pixel488', \n",
    "                         'pixel324', 'pixel211', 'pixel351', 'pixel239', 'pixel713', 'pixel269', 'pixel489', 'pixel516', 'pixel460', \n",
    "                         'pixel212', 'pixel513', 'pixel463', 'pixel457', 'pixel514', \n",
    "                         'pixel240', 'pixel241', 'pixel267', 'pixel573', 'pixel487', 'pixel486', 'pixel484', 'pixel268', 'pixel511', \n",
    "                         'pixel485', 'pixel544', 'pixel456', 'pixel213', 'pixel323'] #borutoSHAP \n",
    "    \n",
    "elif model ==\"powershap\":\n",
    "    processed_shaps_df = pd.read_csv(\"results/gina_prior_PowerSHAP_catboost_results_automatic_mode.csv\")\n",
    "    selected_features = processed_shaps_df[(processed_shaps_df.p_value<0.01)][\"index\"].values\n",
    "\n",
    "elif model ==\"shapicant\":\n",
    "    #shapicant\n",
    "    selected_features = ['pixel103', 'pixel104', 'pixel137', 'pixel152', 'pixel153',\n",
    "       'pixel154', 'pixel157', 'pixel158', 'pixel184', 'pixel211',\n",
    "       'pixel212', 'pixel213', 'pixel238', 'pixel239', 'pixel240',\n",
    "       'pixel241', 'pixel242', 'pixel243', 'pixel249', 'pixel251',\n",
    "       'pixel267', 'pixel268', 'pixel269', 'pixel295', 'pixel296',\n",
    "       'pixel297', 'pixel319', 'pixel323', 'pixel324', 'pixel347',\n",
    "       'pixel348', 'pixel351', 'pixel352', 'pixel358', 'pixel359',\n",
    "       'pixel376', 'pixel377', 'pixel383', 'pixel387', 'pixel403',\n",
    "       'pixel404', 'pixel405', 'pixel410', 'pixel414', 'pixel416',\n",
    "       'pixel427', 'pixel428', 'pixel429', 'pixel432', 'pixel438',\n",
    "       'pixel454', 'pixel455', 'pixel456', 'pixel458', 'pixel459',\n",
    "       'pixel460', 'pixel461', 'pixel462', 'pixel463', 'pixel465',\n",
    "       'pixel483', 'pixel484', 'pixel485', 'pixel487', 'pixel488',\n",
    "       'pixel489', 'pixel490', 'pixel498', 'pixel500', 'pixel511',\n",
    "       'pixel513', 'pixel514', 'pixel515', 'pixel516', 'pixel517',\n",
    "       'pixel518', 'pixel528', 'pixel540', 'pixel541', 'pixel543',\n",
    "       'pixel544', 'pixel545', 'pixel546', 'pixel548', 'pixel569',\n",
    "       'pixel572', 'pixel573', 'pixel576', 'pixel579', 'pixel581',\n",
    "       'pixel584', 'pixel585', 'pixel604', 'pixel607', 'pixel611',\n",
    "       'pixel626', 'pixel627', 'pixel630', 'pixel635', 'pixel680',\n",
    "       'pixel709', 'pixel713', 'pixel714', 'pixel716', 'pixel718',\n",
    "       'pixel719']\n",
    "\n",
    "elif model ==\"chi\":\n",
    "    #chi squared p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[1:-1][np.where(chi2(current_db_train[current_db_train.columns.values[1:-1]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"f_test\":\n",
    "    #f_classif p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[1:-1][np.where(f_classif(current_db_train[current_db_train.columns.values[1:-1]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"default\":\n",
    "    selected_features = list(current_db_train.columns.values[1:-1]) \n",
    "    \n",
    "\n",
    "X_train = current_db_train[selected_features]\n",
    "Y_train = current_db_train[target_col]\n",
    "\n",
    "X_test = current_db_test[selected_features]\n",
    "Y_test = current_db_test[target_col]\n",
    "\n",
    "CB_model = CatBoostClassifier(verbose=False,iterations=250,random_seed=2)#,per_float_feature_quantization=['1:border_count=1024'])\n",
    "#CB_model = LogisticRegression()\n",
    "#CB_model = RandomForestClassifier()#verbose=False,iterations=250,random_seed=2,use_best_model=True)\n",
    "CB_model.fit(X_train,Y_train)\n",
    "        \n",
    "scores_cv_test = test_bootstrap_eval_class(Model = CB_model,test_df = current_db_test.copy(deep=True),bootstrap_its=1000,RS=1,features = selected_features,target_col = target_col)\n",
    "\n",
    "print(model)\n",
    "print(\"TEST\")\n",
    "for key in scores_cv_test:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_test[key]),3))+\" (\"+str(np.round(np.std(scores_cv_test[key]),3))+\")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Class SCENE dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_db = pd.read_csv(\"data/scene.csv\")\n",
    "current_db = current_db.reset_index()\n",
    "\n",
    "Index_col = \"index\"\n",
    "target_col = \"Urban\"\n",
    "\n",
    "current_db[target_col]=current_db[target_col].astype(np.int32)\n",
    "\n",
    "train_idx,val_idx = train_test_split(current_db[Index_col],test_size=0.25,random_state = 1,stratify=current_db[target_col])\n",
    "current_db_train = current_db[current_db[Index_col].isin(train_idx)]\n",
    "current_db_test = current_db[current_db[Index_col].isin(val_idx)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Powershap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = PowerShap(\n",
    "    model = CatBoostClassifier(verbose=0, n_estimators=250,use_best_model=True,class_weights=[1-len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train),len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train)]),\n",
    "    power_iterations=10,automatic=True, limit_automatic=10,verbose=True,stratify=True,#force_convergence = True,\n",
    ")\n",
    "selector.fit(current_db_train[list(current_db_train.columns.values[1:-6])], current_db_train[target_col])\n",
    "t = selector._processed_shaps_df\n",
    "#t.reset_index().to_csv(\"results/scene_PowerSHAP_catboost_results_automatic_mode.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borutashap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(verbose=False,iterations=250,class_weights=[1-len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train),len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train)])\n",
    "\n",
    "# if classification is False it is a Regression problem\n",
    "Feature_Selector = BorutaShap(model=model,\n",
    "                              importance_measure='shap',\n",
    "                              classification=True)\n",
    "\n",
    "Feature_Selector.fit(X=current_db_train[l/ist(current_db_train.columns.values[1:-6])], y=current_db_train[target_col], sample=False,\n",
    "                        train_or_test = 'test', normalize=True,verbose=True)\n",
    "subset = Feature_Selector.Subset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp_db = current_db_train.copy(deep=True)\n",
    "train_idx,val_idx = train_test_split(Inp_db[Index_col],test_size=0.2,random_state = 0)\n",
    "\n",
    "X_train = Inp_db[Inp_db[Index_col].isin(train_idx)].copy(deep=True)[list(current_db_train.columns.values[1:-6])]\n",
    "X_val = Inp_db[Inp_db[Index_col].isin(val_idx)].copy(deep=True)[list(current_db_train.columns.values[1:-6])]\n",
    "Y_train = Inp_db[Inp_db[Index_col].isin(train_idx)][target_col]\n",
    "\n",
    "# LightGBM in RandomForest-like mode (with rows subsampling), without columns subsampling\n",
    "model = CatBoostClassifier(verbose=False,iterations=250,use_best_model=False,class_weights=[1-len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train),len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train)])\n",
    "\n",
    "# This is the class (not its instance) of SHAP's TreeExplainer\n",
    "explainer_type = shap.TreeExplainer\n",
    "\n",
    "# Use PandasSelector with 100 iterations\n",
    "selector = shapicant.PandasSelector(model, explainer_type, random_state=42)\n",
    "\n",
    "# Run the feature selection\n",
    "# If we provide a validation set, SHAP values are computed on it, otherwise they are computed on the training set\n",
    "# We can also provide additional parameters to the underlying estimator's fit method through estimator_params\n",
    "selector.fit(X_train, Y_train, X_validation=X_val)#, estimator_params={\"categorical_feature\": None})\n",
    "\n",
    "# Just get the features list\n",
    "selected_features = selector.get_features()\n",
    "\n",
    "# We can also get the p-values as pandas Series\n",
    "p_values = selector.p_values_\n",
    "\n",
    "np.array(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_model = CatBoostClassifier(verbose=False,iterations=250,class_weights=[1-len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train),len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train)],use_best_model=True)\n",
    "\n",
    "CV_features_arr_final,Metrics_best = classification_forward_feature_selection(shap_model,current_db_train,Index_col,5,0,list(current_db_train.columns.values[1:-6]),target_col,\"AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in [\"powershap\"]:#[\"forward\",\"borutashap\",\"powershap\",\"shapicant\",\"chi\",\"f_test\",\"default\"]:\n",
    "\n",
    "    if model == \"forward\":\n",
    "        selected_features = ['Att240', 'Att200', 'Att88', 'Att46', 'Att214', \n",
    "                   'Att53', 'Att118', 'Att80', 'Att225', 'Att22', 'Att32', 'Att191', 'Att58', 'Att65', 'Att245'] #forward feature selection on AUC\n",
    "\n",
    "    elif model ==\"borutashap\":\n",
    "        selected_features = ['Att83', 'Att240', 'Att226', 'Att223', 'Att45', 'Att98', 'Att89', 'Att241', 'Att222', 'Att245', 'Att82', 'Att72', 'Att22', 'Att91'] #borutoSHAP \n",
    "\n",
    "    elif model ==\"powershap\":\n",
    "        processed_shaps_df = pd.read_csv(\"results/scene_PowerSHAP_catboost_results_automatic_mode.csv\")\n",
    "        selected_features = processed_shaps_df[(processed_shaps_df.p_value<0.01)][\"index\"].values\n",
    "\n",
    "    elif model ==\"shapicant\":\n",
    "        #shapicant\n",
    "        selected_features = ['Att15', 'Att17', 'Att18', 'Att20', 'Att22', 'Att23', 'Att27',\n",
    "           'Att40', 'Att44', 'Att45', 'Att47', 'Att48', 'Att49', 'Att53',\n",
    "           'Att68', 'Att72', 'Att78', 'Att80', 'Att82', 'Att83', 'Att86',\n",
    "           'Att87', 'Att89', 'Att91', 'Att98', 'Att103', 'Att106', 'Att108',\n",
    "           'Att118', 'Att132', 'Att133', 'Att141', 'Att171', 'Att185',\n",
    "           'Att195', 'Att200', 'Att201', 'Att204', 'Att205', 'Att207',\n",
    "           'Att208', 'Att209', 'Att212', 'Att222', 'Att223', 'Att226',\n",
    "           'Att228', 'Att229', 'Att237', 'Att239', 'Att240', 'Att241',\n",
    "           'Att242', 'Att245', 'Att253', 'Att269']\n",
    "\n",
    "    elif model ==\"chi\":\n",
    "        #chi squared p value = 0.01\n",
    "        selected_features = list(current_db_train.columns.values[1:-6][np.where(chi2(current_db_train[current_db_train.columns.values[1:-6]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "    elif model ==\"f_test\":\n",
    "        #f_classif p value = 0.01\n",
    "        selected_features = list(current_db_train.columns.values[1:-6][np.where(f_classif(current_db_train[current_db_train.columns.values[1:-6]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "    elif model ==\"default\":\n",
    "        selected_features = list(current_db_train.columns.values[1:-6])\n",
    "\n",
    "    print(len(selected_features))\n",
    "\n",
    "    CB_model = CatBoostClassifier(verbose=False,iterations=250,random_seed=2,use_best_model=True,\n",
    "                                  class_weights=[1-len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train),len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train)])\n",
    "\n",
    "    scores_cv_train,scores_cv_test = benchmark_classification_cross_validation(Model = CB_model,Inp_db = current_db_train.copy(deep=True),index_col=Index_col,folds=10,RS=0,features = selected_features,target_col = target_col)\n",
    "\n",
    "    print(model)\n",
    "    print(\"TRAIN\")\n",
    "    for key in scores_cv_train:\n",
    "        print(str(key)+\": \"+str(np.round(np.mean(scores_cv_train[key]),3))+\" (\"+str(np.round(np.std(scores_cv_train[key]),3))+\")\")\n",
    "    print(50*\"=\")\n",
    "    print(\"TEST\")\n",
    "    for key in scores_cv_test:\n",
    "        print(str(key)+\": \"+str(np.round(np.mean(scores_cv_test[key]),3))+\" (\"+str(np.round(np.std(scores_cv_test[key]),3))+\")\")\n",
    "    print(100*\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bootstrap testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in [\"powershap\"]:#\"forward\",\"borutashap\",\"powershap\",\"shapicant\",\"chi\",\"f_test\",\"default\"]:\n",
    "\n",
    "\n",
    "    if model == \"forward\":\n",
    "        selected_features = ['Att240', 'Att200', 'Att88', 'Att46', 'Att214', \n",
    "                   'Att53', 'Att118', 'Att80', 'Att225', 'Att22', 'Att32', 'Att191', 'Att58', 'Att65', 'Att245'] #forward feature selection on AUC\n",
    "\n",
    "    elif model ==\"borutashap\":\n",
    "        selected_features = ['Att83', 'Att240', 'Att226', 'Att223', 'Att45', 'Att98', 'Att89', 'Att241', 'Att222', 'Att245', 'Att82', 'Att72', 'Att22', 'Att91'] #borutoSHAP \n",
    "\n",
    "    elif model ==\"powershap\":\n",
    "        processed_shaps_df = pd.read_csv(\"results/scene_PowerSHAP_catboost_results_automatic_mode.csv\")\n",
    "        selected_features = processed_shaps_df[(processed_shaps_df.p_value<0.01)][\"index\"].values\n",
    "\n",
    "    elif model ==\"shapicant\":\n",
    "        #shapicant\n",
    "        selected_features = ['Att15', 'Att17', 'Att18', 'Att20', 'Att22', 'Att23', 'Att27',\n",
    "           'Att40', 'Att44', 'Att45', 'Att47', 'Att48', 'Att49', 'Att53',\n",
    "           'Att68', 'Att72', 'Att78', 'Att80', 'Att82', 'Att83', 'Att86',\n",
    "           'Att87', 'Att89', 'Att91', 'Att98', 'Att103', 'Att106', 'Att108',\n",
    "           'Att118', 'Att132', 'Att133', 'Att141', 'Att171', 'Att185',\n",
    "           'Att195', 'Att200', 'Att201', 'Att204', 'Att205', 'Att207',\n",
    "           'Att208', 'Att209', 'Att212', 'Att222', 'Att223', 'Att226',\n",
    "           'Att228', 'Att229', 'Att237', 'Att239', 'Att240', 'Att241',\n",
    "           'Att242', 'Att245', 'Att253', 'Att269']\n",
    "\n",
    "    elif model ==\"chi\":\n",
    "        #chi squared p value = 0.01\n",
    "        selected_features = list(current_db_train.columns.values[1:-6][np.where(chi2(current_db_train[current_db_train.columns.values[1:-6]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "    elif model ==\"f_test\":\n",
    "        #f_classif p value = 0.01\n",
    "        selected_features = list(current_db_train.columns.values[1:-6][np.where(f_classif(current_db_train[current_db_train.columns.values[1:-6]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "    elif model ==\"default\":\n",
    "        selected_features = list(current_db_train.columns.values[1:-6])\n",
    "\n",
    "    print(len(selected_features))\n",
    "\n",
    "    X_train = current_db_train[selected_features]\n",
    "    Y_train = current_db_train[target_col]\n",
    "\n",
    "    X_test = current_db_test[selected_features]\n",
    "    Y_test = current_db_test[target_col]\n",
    "\n",
    "    CB_model = CatBoostClassifier(verbose=False,iterations=250,random_seed=2,\n",
    "                                  class_weights=[1-len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train),len(current_db_train[current_db_train[target_col] == 0])/len(current_db_train)])\n",
    "    CB_model.fit(X_train,Y_train)\n",
    "\n",
    "    scores_cv_test = test_bootstrap_eval_class(Model = CB_model,test_df = current_db_test.copy(deep=True),bootstrap_its=1000,RS=1,features = selected_features,target_col = target_col)\n",
    "\n",
    "    print(model)\n",
    "    print(\"TEST\")\n",
    "    for key in scores_cv_test:\n",
    "        print(str(key)+\": \"+str(np.round(np.mean(scores_cv_test[key]),3))+\" (\"+str(np.round(np.std(scores_cv_test[key]),3))+\")\")\n",
    "        \n",
    "    print(100*\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CT Location Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_db = pd.read_csv(\"data/slice_localization_data.csv\")\n",
    "current_db = current_db.reset_index()\n",
    "\n",
    "Index_col = \"patientId\"\n",
    "target_col = \"reference\"\n",
    "\n",
    "train_idx,val_idx = train_test_split(current_db[Index_col].unique(),test_size=0.25,random_state = 1)\n",
    "current_db_train = current_db[current_db[Index_col].isin(train_idx)]\n",
    "current_db_test = current_db[current_db[Index_col].isin(val_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### powershap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = PowerShap(\n",
    "    model = CatBoostRegressor(verbose=0, n_estimators=250,use_best_model=True),\n",
    "    power_iterations=10,automatic=True, limit_automatic=10,verbose=True,target_col=target_col,index_col=Index_col,\n",
    ")\n",
    "selector.fit(current_db_train[list(current_db_train.columns.values[2:-1])], current_db_train[target_col])\n",
    "t = selector._processed_shaps_df\n",
    "#t.reset_index().to_csv(\"results/CT_location_PowerSHAP_catboost_results_automatic_mode.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borutashap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(verbose=False,iterations=250)\n",
    "\n",
    "# if classification is False it is a Regression problem\n",
    "Feature_Selector = BorutaShap(model=model,\n",
    "                              importance_measure='shap',\n",
    "                              classification=False)\n",
    "\n",
    "Feature_Selector.fit(X=current_db_train[list(current_db_train.columns.values[2:-1])], y=current_db_train[target_col], sample=False,\n",
    "                        train_or_test = 'test', normalize=True,verbose=True)\n",
    "subset = Feature_Selector.Subset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shapicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp_db = current_db_train.copy(deep=True)\n",
    "train_idx,val_idx = train_test_split(Inp_db[Index_col],test_size=0.2,random_state = 0)\n",
    "\n",
    "X_train = Inp_db[Inp_db[Index_col].isin(train_idx)].copy(deep=True)[list(current_db_train.columns.values[2:-1])]\n",
    "X_val = Inp_db[Inp_db[Index_col].isin(val_idx)].copy(deep=True)[list(current_db_train.columns.values[2:-1])]\n",
    "Y_train = Inp_db[Inp_db[Index_col].isin(train_idx)][target_col]\n",
    "\n",
    "# LightGBM in RandomForest-like mode (with rows subsampling), without columns subsampling\n",
    "model = CatBoostRegressor(verbose=False,iterations=250,use_best_model=False)\n",
    "\n",
    "# This is the class (not its instance) of SHAP's TreeExplainer\n",
    "explainer_type = shap.TreeExplainer\n",
    "\n",
    "# Use PandasSelector with 100 iterations\n",
    "selector = shapicant.PandasSelector(model, explainer_type, random_state=42)\n",
    "\n",
    "# Run the feature selection\n",
    "# If we provide a validation set, SHAP values are computed on it, otherwise they are computed on the training set\n",
    "# We can also provide additional parameters to the underlying estimator's fit method through estimator_params\n",
    "selector.fit(X_train, Y_train, X_validation=X_val)#, estimator_params={\"categorical_feature\": None})\n",
    "\n",
    "# Just get the features list\n",
    "selected_features = selector.get_features()\n",
    "\n",
    "# We can also get the p-values as pandas Series\n",
    "p_values = selector.p_values_\n",
    "\n",
    "np.array(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_model = CatBoostRegressor(verbose=False,iterations=250,use_best_model=True)\n",
    "CV_features_arr_final,Metrics_best = regression_forward_feature_selection(shap_model,current_db_train,Index_col,5,0,current_db_train.drop(columns=[target_col,Index_col]).columns.values,target_col,\"R2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"powershap\"\n",
    "\n",
    "if model == \"forward\":\n",
    "    selected_features = ['value237', 'value378', 'value114', 'value273', 'value172', 'value170',\n",
    "               'value3', 'value116', 'value291', 'value18', 'value226', 'value238', 'value53', 'value142', 'value194', 'value370', \n",
    "               'value299', 'value120', 'value35', 'value10', 'value264', 'value200', 'value316', 'value135', 'value13'] \n",
    "    \n",
    "elif model ==\"borutashap\":\n",
    "    selected_features = ['value53', 'value25', 'value145', 'value116', 'value94', 'value190', 'value21', 'value23', 'value83', \n",
    "                         'value210', 'value118', 'value273', 'value282', 'value122', 'value207', 'value2', 'value226', 'value242', \n",
    "                         'value338', 'value52', 'value132', 'value320', 'value150', 'value140', 'value126', 'value146', 'value124', \n",
    "                         'value236', 'value220', 'value131', 'value4', 'value105', 'value138', 'value248', 'value35', 'value258', \n",
    "                         'value120', 'value100', 'value231', 'value265', 'value134', 'value378', 'value26', 'value215', 'value237', \n",
    "                         'value90', 'value72', 'value117', 'value222', 'value223', 'value160', 'value181', 'value339', 'value110', \n",
    "                         'value81', 'value307', 'value152', 'value201', 'value291', 'value33', 'value141', 'value211', 'value84', \n",
    "                         'value6', 'value216', 'value252', 'value173', 'value112', 'value114', 'value234', 'value280', 'value61', \n",
    "                         'value221', 'value171', 'value130', 'value241', 'value63', 'value95', 'value91', 'value13', 'value143', \n",
    "                         'value218', 'value266', 'value133', 'value256', 'value306', 'value135', 'value123', 'value212', 'value281', \n",
    "                         'value142', 'value151', 'value228', 'value232', 'value14', 'value96', 'value106', 'value235', 'value5', \n",
    "                         'value113', 'value85', 'value300', 'value318', 'value213', 'value292', 'value7', 'value172', 'value191', \n",
    "                         'value272', 'value224', 'value276', 'value125', 'value238', 'value264', 'value251', 'value275', 'value18', \n",
    "                         'value182', 'value298', 'value362', 'value111', 'value230', 'value246', 'value30', 'value200', 'value101', \n",
    "                         'value127', 'value136', 'value305', 'value283', 'value108', 'value8', 'value0', 'value183', 'value22', \n",
    "                         'value314', 'value115', 'value377', 'value170', 'value60', 'value382', 'value227', 'value16', 'value104', \n",
    "                         'value64', 'value299', 'value121', 'value3', 'value214', 'value308', 'value322', 'value174', 'value331', \n",
    "                         'value54', 'value233', 'value274', 'value44', 'value370', 'value180', 'value225', 'value102', 'value192']\n",
    "    \n",
    "elif model ==\"powershap\":\n",
    "    processed_shaps_df = pd.read_csv(\"results/CT_location_PowerSHAP_catboost_results_automatic_mode.csv\")\n",
    "    selected_features = processed_shaps_df[(processed_shaps_df.p_value<0.01)][\"index\"].values\n",
    "\n",
    "elif model ==\"shapicant\":\n",
    "    #shapicant\n",
    "    selected_features = ['value0', 'value2', 'value3', 'value4', 'value5', 'value8',\n",
    "       'value18', 'value28', 'value29', 'value38', 'value47', 'value53',\n",
    "       'value55', 'value60', 'value63', 'value88', 'value106', 'value108',\n",
    "       'value110', 'value114', 'value115', 'value116', 'value118',\n",
    "       'value132', 'value135', 'value136', 'value137', 'value138',\n",
    "       'value145', 'value150', 'value167', 'value170', 'value172',\n",
    "       'value182', 'value183', 'value197', 'value200', 'value209',\n",
    "       'value210', 'value212', 'value213', 'value215', 'value225',\n",
    "       'value226', 'value227', 'value228', 'value230', 'value233',\n",
    "       'value237', 'value238', 'value241', 'value251', 'value264',\n",
    "       'value269', 'value270', 'value272', 'value273', 'value280',\n",
    "       'value291', 'value295', 'value300', 'value310', 'value311',\n",
    "       'value318', 'value319', 'value322', 'value334', 'value338',\n",
    "       'value341', 'value367', 'value370', 'value377', 'value378',\n",
    "       'value382']\n",
    "\n",
    "elif model ==\"f_test\":\n",
    "    #f_classif p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[2:-1][np.where(f_regression(current_db_train[current_db_train.columns.values[2:-1]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"default\":\n",
    "    selected_features = list(current_db_train.columns.values[2:-1])\n",
    "\n",
    "print(len(selected_features))\n",
    "\n",
    "CB_model = CatBoostRegressor(verbose=False,iterations=250,random_seed=2,use_best_model=True)\n",
    "\n",
    "scores_cv_train,scores_cv_test = benchmark_regression_cross_validation(Model = CB_model,Inp_db = current_db_train.copy(deep=True),index_col=Index_col,folds=10,RS=0,features = selected_features,target_col = target_col)\n",
    "\n",
    "print(model)\n",
    "print(\"TRAIN\")\n",
    "for key in scores_cv_train:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_train[key]),3))+\" (\"+str(np.round(np.std(scores_cv_train[key]),3))+\")\")\n",
    "print(50*\"=\")\n",
    "print(\"TEST\")\n",
    "for key in scores_cv_test:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_test[key]),3))+\" (\"+str(np.round(np.std(scores_cv_test[key]),3))+\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bootstrap testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"powershap\"\n",
    "\n",
    "if model == \"forward\":\n",
    "    selected_features = ['value237', 'value378', 'value114', 'value273', 'value172', 'value170',\n",
    "               'value3', 'value116', 'value291', 'value18', 'value226', 'value238', 'value53', 'value142', 'value194', 'value370', \n",
    "               'value299', 'value120', 'value35', 'value10', 'value264', 'value200', 'value316', 'value135', 'value13'] \n",
    "    \n",
    "elif model ==\"borutashap\":\n",
    "    selected_features = ['value2', 'value171', 'value32', 'value141', 'value252', 'value192', 'value133', 'value8', 'value155', \n",
    "                         'value265', 'value135', 'value223', 'value292', 'value290', 'value151', 'value112', 'value377', 'value233', \n",
    "                         'value26', 'value220', 'value30', 'value140', 'value230', 'value248', 'value211', 'value85', 'value172', \n",
    "                         'value221', 'value22', 'value145', 'value331', 'value251', 'value3', 'value222', 'value131', 'value13', \n",
    "                         'value160', 'value370', 'value114', 'value228', 'value276', 'value16', 'value0', 'value111', 'value117', \n",
    "                         'value280', 'value104', 'value154', 'value273', 'value134', 'value237', 'value224', 'value212', 'value5', \n",
    "                         'value83', 'value116', 'value184', 'value120', 'value182', 'value136', 'value242', 'value235', 'value267', \n",
    "                         'value190', 'value215', 'value339', 'value84', 'value371', 'value14', 'value241', 'value35', 'value214', \n",
    "                         'value298', 'value61', 'value299', 'value275', 'value300', 'value110', 'value281', 'value291', 'value161', \n",
    "                         'value274', 'value362', 'value201', 'value308', 'value91', 'value4', 'value53', 'value81', 'value34', \n",
    "                         'value103', 'value183', 'value207', 'value174', 'value283', 'value226', 'value52', 'value122', 'value258', \n",
    "                         'value146', 'value150', 'value127', 'value288', 'value92', 'value105', 'value232', 'value236', 'value101', \n",
    "                         'value225', 'value6', 'value227', 'value170', 'value216', 'value118', 'value64', 'value191', 'value180', \n",
    "                         'value7', 'value256', 'value113', 'value213', 'value259', 'value63', 'value132', 'value123', 'value312', \n",
    "                         'value181', 'value138', 'value378', 'value200', 'value210', 'value125', 'value369', 'value106', 'value264', \n",
    "                         'value90', 'value282', 'value307', 'value130', 'value219', 'value152', 'value126', 'value244', \n",
    "                         'value173', 'value142', 'value143', 'value124', 'value60', 'value257', 'value234', \n",
    "                         'value272', 'value115', 'value108', 'value266', 'value18', 'value44', 'value33', 'value314', 'value100', 'value42', 'value231', 'value260', 'value320']\n",
    "    \n",
    "elif model ==\"powershap\":\n",
    "    processed_shaps_df = pd.read_csv(\"results/CT_location_PowerSHAP_catboost_results_automatic_mode.csv\")\n",
    "    selected_features = processed_shaps_df[(processed_shaps_df.p_value<0.01)][\"index\"].values\n",
    "\n",
    "\n",
    "elif model ==\"shapicant\":\n",
    "    #shapicant\n",
    "    selected_features = ['value0', 'value2', 'value3', 'value4', 'value5', 'value8',\n",
    "       'value18', 'value28', 'value29', 'value38', 'value47', 'value53',\n",
    "       'value55', 'value60', 'value63', 'value88', 'value106', 'value108',\n",
    "       'value110', 'value114', 'value115', 'value116', 'value118',\n",
    "       'value132', 'value135', 'value136', 'value137', 'value138',\n",
    "       'value145', 'value150', 'value167', 'value170', 'value172',\n",
    "       'value182', 'value183', 'value197', 'value200', 'value209',\n",
    "       'value210', 'value212', 'value213', 'value215', 'value225',\n",
    "       'value226', 'value227', 'value228', 'value230', 'value233',\n",
    "       'value237', 'value238', 'value241', 'value251', 'value264',\n",
    "       'value269', 'value270', 'value272', 'value273', 'value280',\n",
    "       'value291', 'value295', 'value300', 'value310', 'value311',\n",
    "       'value318', 'value319', 'value322', 'value334', 'value338',\n",
    "       'value341', 'value367', 'value370', 'value377', 'value378',\n",
    "       'value382']\n",
    "\n",
    "elif model ==\"f_test\":\n",
    "    #f_classif p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[2:-1][np.where(f_regression(current_db_train[current_db_train.columns.values[2:-1]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"default\":\n",
    "    selected_features = list(current_db_train.columns.values[2:-1])\n",
    "\n",
    "X_train = current_db_train[selected_features]\n",
    "Y_train = current_db_train[target_col]\n",
    "\n",
    "X_test = current_db_test[selected_features]\n",
    "Y_test = current_db_test[target_col]\n",
    "\n",
    "CB_model = CatBoostRegressor(verbose=100,iterations=250,random_seed=2)#,per_float_feature_quantization=['1:border_count=1024'])\n",
    "CB_model.fit(X_train,Y_train)\n",
    "        \n",
    "scores_cv_test = test_bootstrap_eval_regres(Model = CB_model,test_df = current_db_test.copy(deep=True),bootstrap_its=100,RS=1,features = selected_features,target_col = target_col)\n",
    "\n",
    "print(model)\n",
    "print(\"TEST\")\n",
    "for key in scores_cv_test:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_test[key]),3))+\" (\"+str(np.round(np.std(scores_cv_test[key]),3))+\")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appliances Energy Production Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_db = pd.read_csv(\"data/energydata_complete.csv\")\n",
    "current_db = current_db.reset_index()\n",
    "\n",
    "Index_col = \"index\"\n",
    "target_col = \"Appliances\"\n",
    "\n",
    "train_idx,val_idx = train_test_split(current_db[Index_col],test_size=0.25,random_state = 1)\n",
    "current_db_train = current_db[current_db[Index_col].isin(train_idx)]\n",
    "current_db_test = current_db[current_db[Index_col].isin(val_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### powershap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = PowerShap(\n",
    "    model = CatBoostRegressor(verbose=0, n_estimators=250,use_best_model=True),\n",
    "    power_iterations=10,automatic=True, limit_automatic=10,verbose=True,target_col=target_col,index_col=Index_col,\n",
    ")\n",
    "selector.fit(current_db_train[list(current_db_train.columns.values[3:])], current_db_train[target_col])\n",
    "t = selector._processed_shaps_df\n",
    "#t.reset_index().to_csv(\"results/appliances_PowerSHAP_catboost_results_automatic_mode.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### borutashap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(verbose=False,iterations=250)\n",
    "\n",
    "# if classification is False it is a Regression problem\n",
    "Feature_Selector = BorutaShap(model=model,\n",
    "                              importance_measure='shap',\n",
    "                              classification=False)\n",
    "\n",
    "Feature_Selector.fit(X=current_db_train[list(current_db_train.columns.values[3:])], y=current_db_train[target_col], sample=False,\n",
    "                        train_or_test = 'test', normalize=True,verbose=True)\n",
    "subset = Feature_Selector.Subset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shapicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp_db = current_db_train.copy(deep=True)\n",
    "train_idx,val_idx = train_test_split(Inp_db[Index_col],test_size=0.2,random_state = 0)\n",
    "\n",
    "X_train = Inp_db[Inp_db[Index_col].isin(train_idx)].copy(deep=True)[list(current_db_train.columns.values[3:])]\n",
    "X_val = Inp_db[Inp_db[Index_col].isin(val_idx)].copy(deep=True)[list(current_db_train.columns.values[3:])]\n",
    "Y_train = Inp_db[Inp_db[Index_col].isin(train_idx)][target_col]\n",
    "\n",
    "# LightGBM in RandomForest-like mode (with rows subsampling), without columns subsampling\n",
    "model = CatBoostRegressor(verbose=False,iterations=250,use_best_model=False)\n",
    "\n",
    "# This is the class (not its instance) of SHAP's TreeExplainer\n",
    "explainer_type = shap.TreeExplainer\n",
    "\n",
    "# Use PandasSelector with 100 iterations\n",
    "selector = shapicant.PandasSelector(model, explainer_type, random_state=42)\n",
    "\n",
    "# Run the feature selection\n",
    "# If we provide a validation set, SHAP values are computed on it, otherwise they are computed on the training set\n",
    "# We can also provide additional parameters to the underlying estimator's fit method through estimator_params\n",
    "selector.fit(X_train, Y_train, X_validation=X_val)#, estimator_params={\"categorical_feature\": None})\n",
    "\n",
    "# Just get the features list\n",
    "selected_features = selector.get_features()\n",
    "\n",
    "# We can also get the p-values as pandas Series\n",
    "p_values = selector.p_values_\n",
    "\n",
    "np.array(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_model = CatBoostRegressor(verbose=False,iterations=250,use_best_model=True)\n",
    "CV_features_arr_final,Metrics_best = regression_forward_feature_selection(shap_model,current_db_train,Index_col,5,0,current_db_train.columns.values[3:],target_col,\"R2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"powershap\"\n",
    "\n",
    "if model == \"forward\":\n",
    "    selected_features = ['lights', 'T9', 'Press_mm_hg', 'T_out', 'RH_2', 'T4', 'T8', 'RH_8', 'RH_5', 'RH_4', 'T7', 'Tdewpoint', 'T6']\n",
    "    \n",
    "elif model ==\"borutashap\":\n",
    "    selected_features = ['RH_3', 'T5', 'RH_8', 'T4', 'Tdewpoint', 'T3', 'lights', 'RH_1', \n",
    "                         'T6', 'T2', 'RH_2', 'RH_4', 'T9', 'RH_5', 'RH_7', 'T8', 'RH_9', 'T7', 'RH_6', 'T_out', 'T1', 'Press_mm_hg', 'RH_out', 'Windspeed']\n",
    "    \n",
    "elif model ==\"powershap\":\n",
    "    processed_shaps_df = pd.read_csv(\"results/appliances_PowerSHAP_catboost_results_automatic_mode.csv\")\n",
    "    selected_features = processed_shaps_df[(processed_shaps_df.p_value<0.01)][\"index\"].values\n",
    "\n",
    "elif model ==\"shapicant\":\n",
    "    #shapicant\n",
    "    selected_features = ['lights', 'T1', 'RH_1', 'RH_2', 'T3', 'RH_3', 'RH_6', 'RH_8',\n",
    "       'Press_mm_hg', 'Windspeed']\n",
    "\n",
    "elif model ==\"f_test\":\n",
    "    #f_classif p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[3:][np.where(f_regression(current_db_train[current_db_train.columns.values[3:]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"default\":\n",
    "    selected_features = list(current_db_train.columns.values[3:])\n",
    "\n",
    "print(len(selected_features))\n",
    "\n",
    "CB_model = CatBoostRegressor(verbose=False,iterations=250,random_seed=2)\n",
    "\n",
    "scores_cv_train,scores_cv_test = benchmark_regression_cross_validation(Model = CB_model,Inp_db = current_db_train.copy(deep=True),index_col=Index_col,folds=10,RS=0,features = selected_features,target_col = target_col)\n",
    "\n",
    "print(model)\n",
    "print(\"TRAIN\")\n",
    "for key in scores_cv_train:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_train[key]),3))+\" (\"+str(np.round(np.std(scores_cv_train[key]),3))+\")\")\n",
    "print(50*\"=\")\n",
    "print(\"TEST\")\n",
    "for key in scores_cv_test:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_test[key]),3))+\" (\"+str(np.round(np.std(scores_cv_test[key]),3))+\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bootstrap testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"powershap\"\n",
    "\n",
    "if model == \"forward\":\n",
    "    selected_features = ['lights', 'T9', 'Press_mm_hg', 'T_out', 'RH_2', 'T4', 'T8', 'RH_8', 'RH_5', 'RH_4', 'T7', 'Tdewpoint', 'T6']\n",
    "    \n",
    "elif model ==\"borutashap\":\n",
    "    selected_features = ['RH_3', 'T5', 'RH_8', 'T4', 'Tdewpoint', 'T3', 'lights', 'RH_1', \n",
    "                         'T6', 'T2', 'RH_2', 'RH_4', 'T9', 'RH_5', 'RH_7', 'T8', 'RH_9', 'T7', 'RH_6', 'T_out', 'T1', 'Press_mm_hg', 'RH_out', 'Windspeed']\n",
    "    \n",
    "elif model ==\"powershap\":\n",
    "    processed_shaps_df = pd.read_csv(\"results/appliances_PowerSHAP_catboost_results_automatic_mode.csv\")\n",
    "    selected_features = processed_shaps_df[(processed_shaps_df.p_value<0.01)][\"index\"].values\n",
    "\n",
    "elif model ==\"shapicant\":\n",
    "    #shapicant\n",
    "    selected_features = ['lights', 'T1', 'RH_1', 'RH_2', 'T3', 'RH_3', 'RH_6', 'RH_8',\n",
    "       'Press_mm_hg', 'Windspeed']\n",
    "\n",
    "elif model ==\"f_test\":\n",
    "    #f_classif p value = 0.01\n",
    "    selected_features = list(current_db_train.columns.values[3:][np.where(f_regression(current_db_train[current_db_train.columns.values[3:]],current_db_train[target_col])[1]<0.01)[0]])\n",
    "\n",
    "elif model ==\"default\":\n",
    "    selected_features = list(current_db_train.columns.values[3:])\n",
    "\n",
    "print(len(selected_features))\n",
    "\n",
    "X_train = current_db_train[selected_features]\n",
    "Y_train = current_db_train[target_col]\n",
    "\n",
    "X_test = current_db_test[selected_features]\n",
    "Y_test = current_db_test[target_col]\n",
    "\n",
    "CB_model = CatBoostRegressor(verbose=False,iterations=250,random_seed=2)#,per_float_feature_quantization=['1:border_count=1024'])\n",
    "CB_model.fit(X_train,Y_train)\n",
    "        \n",
    "scores_cv_test = test_bootstrap_eval_regres(Model = CB_model,test_df = current_db_test.copy(deep=True),bootstrap_its=1000,RS=1,features = selected_features,target_col = target_col)\n",
    "\n",
    "print(model)\n",
    "print(\"TEST\")\n",
    "for key in scores_cv_test:\n",
    "    print(str(key)+\": \"+str(np.round(np.mean(scores_cv_test[key]),3))+\" (\"+str(np.round(np.std(scores_cv_test[key]),3))+\")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
